#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åƒåœ¾åˆ†ç±»æ¨¡å‹æ¼”ç¤ºè„šæœ¬
å¿«é€Ÿæµ‹è¯•å•å¼ å›¾ç‰‡çš„åˆ†ç±»ç»“æœ
"""

import os
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import argparse

class ImprovedGarbageClassificationCNN(nn.Module):
    """åƒåœ¾åˆ†ç±»CNNæ¨¡å‹"""
    
    def __init__(self, num_classes=4, use_pretrained=True, model_name='resnet18'):
        super(ImprovedGarbageClassificationCNN, self).__init__()
        self.num_classes = num_classes
        self.use_pretrained = use_pretrained
        
        if use_pretrained:
            if model_name == 'resnet18':
                # åˆ›å»ºResNet18æ¨¡å‹ç»“æ„
                self.backbone = models.resnet18(pretrained=False)
                # åŠ è½½æœ¬åœ°ResNet18æƒé‡
                if os.path.exists('resnet18-f37072fd.pth'):
                    state_dict = torch.load('resnet18-f37072fd.pth', map_location='cpu')
                    self.backbone.load_state_dict(state_dict)
                # å†»ç»“å¤§éƒ¨åˆ†å±‚
                for param in list(self.backbone.parameters())[:-10]:
                    param.requires_grad = False
                num_features = self.backbone.fc.in_features
                self.backbone.fc = nn.Identity()
            else:
                raise ValueError(f"Unsupported model: {model_name}")
            
            # è‡ªå®šä¹‰åˆ†ç±»å¤´
            self.classifier = nn.Sequential(
                nn.BatchNorm1d(num_features),
                nn.Dropout(0.5),
                nn.Linear(num_features, 512),
                nn.BatchNorm1d(512),
                nn.ReLU(inplace=True),
                nn.Dropout(0.3),
                nn.Linear(512, 256),
                nn.BatchNorm1d(256),
                nn.ReLU(inplace=True),
                nn.Dropout(0.2),
                nn.Linear(256, num_classes)
            )
    
    def forward(self, x):
        features = self.backbone(x)
        if len(features.shape) > 2:
            features = features.view(features.size(0), -1)
        output = self.classifier(features)
        return output


class GarbageClassifier:
    """åƒåœ¾åˆ†ç±»å™¨"""
    
    def __init__(self, model_path='best_improved_model.pth'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.class_names = ['biological', 'hazardous_waste', 'others', 'recyclable']
        self.class_names_chinese = ['ç”Ÿç‰©åƒåœ¾', 'æœ‰å®³åƒåœ¾', 'å…¶ä»–åƒåœ¾', 'å¯å›æ”¶åƒåœ¾']
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model(model_path)
        
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            model = ImprovedGarbageClassificationCNN(
                num_classes=len(self.class_names),
                use_pretrained=True,
                model_name='resnet18'
            )
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            if not os.path.exists(model_path):
                print(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return None
            
            # åŠ è½½æ¨¡å‹æƒé‡
            checkpoint = torch.load(model_path, map_location=self.device)
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            
            model = model.to(self.device)
            model.eval()
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
            print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
            return model
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def predict(self, image_path):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªæˆåŠŸåŠ è½½")
            return None
        
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                predicted_class = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class].item()
            
            # è¿”å›ç»“æœ
            result = {
                'predicted_class': predicted_class,
                'class_name': self.class_names[predicted_class],
                'class_name_chinese': self.class_names_chinese[predicted_class],
                'confidence': confidence,
                'probabilities': probabilities.cpu().numpy()
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def print_result(self, result, image_path):
        """æ‰“å°é¢„æµ‹ç»“æœ"""
        print(f"\nğŸ“¸ å›¾ç‰‡: {image_path}")
        print("=" * 50)
        print(f"ğŸ¯ é¢„æµ‹ç±»åˆ«: {result['class_name_chinese']} ({result['class_name']})")
        print(f"ğŸ”¥ ç½®ä¿¡åº¦: {result['confidence']:.2%}")
        print("\nğŸ“Š å„ç±»åˆ«æ¦‚ç‡:")
        
        for i, (name_en, name_cn) in enumerate(zip(self.class_names, self.class_names_chinese)):
            prob = result['probabilities'][i]
            bar = "â–ˆ" * int(prob * 20)  # ç®€å•çš„è¿›åº¦æ¡
            print(f"   {name_cn:6} | {prob:.2%} {bar}")
        print("=" * 50)


def main():
    parser = argparse.ArgumentParser(description='åƒåœ¾åˆ†ç±»æ¨¡å‹æ¼”ç¤º')
    parser.add_argument('image_path', help='è¦åˆ†ç±»çš„å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--model', default='best_improved_model.pth', 
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: best_improved_model.pth)')
    
    args = parser.parse_args()
    
    print("ğŸ—‘ï¸  åƒåœ¾åˆ†ç±»æ¨¡å‹æ¼”ç¤º")
    print("=" * 50)
    
    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {args.image_path}")
        return
    
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = GarbageClassifier(args.model)
    
    # è¿›è¡Œé¢„æµ‹
    result = classifier.predict(args.image_path)
    
    if result:
        classifier.print_result(result, args.image_path)
    else:
        print("âŒ é¢„æµ‹å¤±è´¥")


if __name__ == "__main__":
    main() 